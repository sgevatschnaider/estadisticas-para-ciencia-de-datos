# M√ìDULO I: Probabilidad Multivariante y Geometr√≠a de Datos

<p align="center">
  <img src="../../../assets/portada_probabilidad.gif" alt="Visualizaci√≥n: Covarianza y Elipsoides" width="100%">
  <br>
  <sub style="font-size: 14px;">
    <b>√Ålgebra Lineal Aleatoria</b> &nbsp;|&nbsp;
    <b>Normal Multivariante (MVN)</b> &nbsp;|&nbsp;
    <b>Concentraci√≥n de la Medida</b>
  </sub>
</p>

---

## üéØ Objetivos de Aprendizaje (Engineering Track)

Al completar este m√≥dulo, dejar√°s de ver la probabilidad como "lanzar dados" y pasar√°s a verla como **geometr√≠a en alta dimensi√≥n**. Podr√°s:

- **Geometrica de Datos:** Entender la correlaci√≥n como el coseno del √°ngulo entre vectores aleatorios (Espacios de Hilbert).
- **Ingenier√≠a de la MVN:** Dominar la **Normal Multivariante**, la distribuci√≥n m√°s importante en Machine Learning y Filtros de Kalman.
- **Pre-procesamiento:** Implementar **Whitening (Blanqueo)** y PCA desde cero usando descomposici√≥n espectral ($\Sigma = U\Lambda U^T$).
- **Detecci√≥n de Anomal√≠as:** Utilizar la **Distancia de Mahalanobis** para encontrar outliers en dimensiones $d > 3$.
- **Garant√≠as Te√≥ricas:** Aplicar desigualdades de concentraci√≥n (**Chebyshev, Hoeffding**) para acotar errores en algoritmos de aprendizaje.

---

## üõ†Ô∏è Stack Tecnol√≥gico

Requisitos para este m√≥dulo:

- **Core:** `numpy` (√°lgebra lineal), `scipy.stats` (distribuciones).
- **Visualizaci√≥n:** `matplotlib`, `seaborn` (est√°tica), `plotly` (interactiva 3D).
- **Simulaci√≥n:** `statsmodels` (opcional).

```bash
# Instalaci√≥n del entorno
pip install numpy scipy matplotlib seaborn plotly pandas

```

---

## üß™ Laboratorio Interactivo (Notebooks & Apps)

Esta secci√≥n contiene los recursos principales. Los **Notebooks** combinan teor√≠a dura (Wasserman/Kenett) con c√≥digo, y las **Apps HTML** son simuladores visuales standalone.

| üìÑ Recurso | üì• Acceso |
|---|---|
| **Variables Aleatorias y Teor√≠a de la Medida (Lecci√≥n Interactiva)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Cuaderno te√≥rico en Python que traduce las intuiciones visuales a la formalidad matem√°tica pura. Define rigurosamente la variable aleatoria como una funci√≥n medible (pushforward), explora la descomposici√≥n de Lebesgue, transformaciones con Jacobiano, esperanza matem√°tica y geometr√≠a en el espacio L2.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/87ab9a48374af5483e119978bfa60eb0bf0535bd/src/classroom/probabilidad/notebooks/01_Fundamentos_Matematicos_Probabilidad.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/87ab9a48374af5483e119978bfa60eb0bf0535bd/src/classroom/probabilidad/notebooks/01_Fundamentos_Matematicos_Probabilidad.ipynb) |

| üìÑ Recurso | üì• Acceso |
|---|---|
| **Fase 1: Del Bit al Continuo (Simulador)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Simulador interactivo que demuestra la equivalencia fundamental entre tirar una moneda (bits) y construir un n√∫mero real en el intervalo [0,1]. Rompe la intuici√≥n discreta y establece la base para entender c√≥mo secuencias infinitas definen variables continuas, un concepto vital para PRNGs y transformadas inversas.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_moneda.html) <br><br> [![Ver Simulaci√≥n Interactiva](https://img.shields.io/badge/Ver%20Simulaci%C3%B3n-Interactiva-green?style=for-the-badge&logo=blogger)](https://htmlpreview.github.io/?https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_moneda.html) |
| **Fase 2: Conjuntos Cil√≠ndricos (Simulador)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Herramienta visual que explica c√≥mo fijar condiciones finitas iniciales crea "bloques" de volumen exacto (conjuntos cil√≠ndricos) en el espacio continuo. Prepara la intuici√≥n para comprender las œÉ-√°lgebras y c√≥mo se atrapan porciones de medida probabil√≠stica, simulando 10,000 secuencias en tiempo real.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_cilindros.html) <br><br> [![Ver Simulaci√≥n Interactiva](https://img.shields.io/badge/Ver%20Simulaci%C3%B3n-Interactiva-green?style=for-the-badge&logo=blogger)](https://htmlpreview.github.io/?https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_cilindros.html) |
| **Fase 3: La Paradoja del Cero (Simulador)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Simulador que escala el problema del cumplea√±os al infinito para ilustrar el colapso de la probabilidad puntual. Demuestra interactivamente que el hecho de que un evento continuo tenga probabilidad de cero (medida de Lebesgue nula) no significa que sea topol√≥gicamente imposible.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_paradoja_del_cero.html) <br><br> [![Ver Simulaci√≥n Interactiva](https://img.shields.io/badge/Ver%20Simulaci%C3%B3n-Interactiva-green?style=for-the-badge&logo=blogger)](https://htmlpreview.github.io/?https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_paradoja_del_cero.html) |
| **Fase 4: √Årbol Binario en Disco de Poincar√© (Simulador)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Representaci√≥n avanzada que sit√∫a el espacio muestral de secuencias como un Grafo de Cayley incrustado en geometr√≠a hiperb√≥lica. Ilustra visualmente c√≥mo el espacio muestral continuo reside en el l√≠mite infinito (el polvo de Cantor), d√°ndole una interpretaci√≥n geom√©trica rigurosa al azar.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_poincare_tree.html) <br><br> [![Ver Simulaci√≥n Interactiva](https://img.shields.io/badge/Ver%20Simulaci%C3%B3n-Interactiva-green?style=for-the-badge&logo=blogger)](https://htmlpreview.github.io/?https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_poincare_tree.html) |
| **Fase 5: Variables Aleatorias y Teor√≠a de la Medida (Lecci√≥n Interactiva)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Cuaderno te√≥rico en Python que traduce las intuiciones visuales a la formalidad matem√°tica pura. Define rigurosamente la variable aleatoria como una funci√≥n medible (pushforward), explora la descomposici√≥n de Lebesgue, transformaciones con Jacobiano, esperanza matem√°tica y geometr√≠a en el espacio L2.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/notebooks/01_Fundamentos_Matematicos_Probabilidad.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/notebooks/01_Fundamentos_Matematicos_Probabilidad.ipynb) |
| **Fase 6: La M√°quina de la Creaci√≥n (Simulador)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Aplicaci√≥n pr√°ctica de toda la teor√≠a anterior utilizando el Teorema de la Transformada Inversa. El simulador muestra c√≥mo una distribuci√≥n uniforme generada en [0,1] se mapea a trav√©s de la funci√≥n probit para hacer emerger la Campana de Gauss en tiempo real.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_creation_machine.html) <br><br> [![Ver Simulaci√≥n Interactiva](https://img.shields.io/badge/Ver%20Simulaci%C3%B3n-Interactiva-green?style=for-the-badge&logo=blogger)](https://htmlpreview.github.io/?https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_creation_machine.html) |
| **Fase 7: El Guardi√°n de las Colas (Simulador)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Simulador interactivo sobre las desigualdades de concentraci√≥n de Markov y Chebyshev. Permite explorar visualmente c√≥mo acotar probabilidades en las colas sin conocer la distribuci√≥n subyacente, y demuestra el concepto de cota ajustada mediante un caso l√≠mite con distribuciones mixtas (Spike).</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_Chebyshev_Markov.html) <br><br> [![Ver Simulaci√≥n Interactiva](https://img.shields.io/badge/Ver%20Simulaci%C3%B3n-Interactiva-green?style=for-the-badge&logo=blogger)](https://htmlpreview.github.io/?https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_Chebyshev_Markov.html) |
| **Fase 8: La F√°brica de √Åtomos (Simulador)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Laboratorio visual que explica la diferencia fundamental entre censurar y truncar datos. Muestra c√≥mo colapsar valores extremos crea masas puntuales ("√°tomos") en distribuciones continuas, ilustrando intuitivamente la necesidad matem√°tica de la Teor√≠a de la Medida de Lebesgue.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Fabrica_de_atomos.html) <br><br> [![Ver Simulaci√≥n Interactiva](https://img.shields.io/badge/Ver%20Simulaci%C3%B3n-Interactiva-green?style=for-the-badge&logo=blogger)](https://htmlpreview.github.io/?https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Fabrica_de_atomos.html) |
| **Fase 9: El Juego de las Monedas Infinitas (Simulador)** <br><br> <details><summary><strong>Resumen:</strong> <em>(haz clic para expandir/colapsar)</em></summary><p>Simulador avanzado que contrasta las integrales de Riemann y Lebesgue. A trav√©s de la Funci√≥n de Dirichlet y la construcci√≥n de Conjuntos Cil√≠ndricos mediante lanzamientos de moneda, demuestra c√≥mo Lebesgue agrupa por preimagen para unificar el concepto de Esperanza Matem√°tica.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_lebesgue_monedas.html) <br><br> [![Ver Simulaci√≥n Interactiva](https://img.shields.io/badge/Ver%20Simulaci%C3%B3n-Interactiva-green?style=for-the-badge&logo=blogger)](https://htmlpreview.github.io/?https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_lebesgue_monedas.html) |

---
## üé• Material Audiovisual Complementario (The Video Lectures)

Para consolidar la intuici√≥n geom√©trica y las demostraciones formales de los simuladores, esta es la curadur√≠a definitiva de clases en video. Ideal para repasar conceptos complejos de topolog√≠a, teor√≠a de la medida y econometr√≠a aplicados a la ciencia de datos.

| üé¨ Tema y Concepto Clave | üë®‚Äçüè´ Canal / Autor | üîó Enlace |
| :--- | :--- | :--- |
| **Teor√≠a de la Medida e Integral de Lebesgue**<br><sub>*Complemento para entender por qu√© la integraci√≥n de Riemann falla en el continuo y c√≥mo Lebesgue agrupa por preimagen.*</sub> | **The Bright Side of Mathematics**<br><sub>*Measure Theory (Curso Completo)*</sub> | [![Ver Playlist](https://img.shields.io/badge/Playlist-YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/playlist?list=PLBh2i93oe2qvMVqAzsX1Kuv6-4fjazZ8j) |
| **Desigualdades de Concentraci√≥n**<br><sub>*La demostraci√≥n rigurosa de Markov y Chebyshev, fundamental para entender las cotas de error en algoritmos.*</sub> | **Steve Brunton**<br><sub>*Chebyshev's Inequality*</sub><br><br>**MIT OpenCourseWare**<br><sub>*Prof. John Tsitsiklis (Lecture 20)*</sub> | [![Ver Video](https://img.shields.io/badge/Video-YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=otCHN3s52ho) <br><br> [![Ver Video](https://img.shields.io/badge/Video-YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=nrDkb2MAwSA) |
| **M√©todo de la Transformada Inversa**<br><sub>*La matem√°tica detr√°s de la simulaci√≥n de variables aleatorias usando la funci√≥n cuantil ($F^{-1}$).*</sub> | **Ben Lambert**<br><sub>*Inverse transform sampling*</sub><br><br>**ritvikmath**<br><sub>*Inverse Transform Sampling*</sub> | [![Ver Video](https://img.shields.io/badge/Video-YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=rnBbYsysPaU) <br><br> [![Ver Video](https://img.shields.io/badge/Video-YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=9ixzzPQWuAY) |
| **Topolog√≠a del Continuo y Medida Cero**<br><sub>*Paradojas del espacio muestral continuo, mapeos infinitos y por qu√© probabilidad 0 $\neq$ imposible.*</sub> | **3Blue1Brown**<br><sub>*Probabilities of continuous spaces*</sub><br><br>**Vsauce**<br><sub>*How To Count Past Infinity*</sub> | [![Ver Video](https://img.shields.io/badge/Video-YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=ZA4JkHKZM50) <br><br> [![Ver Video](https://img.shields.io/badge/Video-YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=SrU9YDoXE88) |
| **Censura vs. Truncamiento (Econometr√≠a)**<br><sub>*Entendiendo la formaci√≥n de √°tomos (masas puntuales) en las colas, esencial para los Modelos Tobit.*</sub> | **Anders Munk-Nielsen**<br><sub>*The Tobit Model*</sub><br><br>**Jake Clifton / Ben Lambert**<br><sub>*Econometrics II (Playlist)*</sub> | [![Ver Video](https://img.shields.io/badge/Video-YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=IwsE8Rr6l6E) <br><br> [![Ver Playlist](https://img.shields.io/badge/Playlist-YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/playlist?list=PLLZ4uVeiDmR_rzu-uYl9A5BrmvTKtH_aB) |

| üìÑ Recurso | üì• Acceso |
|---|---|
| **Glosario Avanzado: Probabilidad & Teor√≠a de la Medida** <br> <details><summary><strong>Resumen:</strong> <small><em>(haz clic para expandir)</em></small></summary><p>Diccionario interactivo con 46 t√©rminos rigurosos que fundamentan la probabilidad moderna. Abarca desde la integral de Lebesgue y la terna de Kolmogorov, hasta la paradoja del cero y las desigualdades de concentraci√≥n. Incluye definiciones matem√°ticas precisas y ejemplos concretos esenciales para ciencia de datos.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_Glosario.html) <br> [![Ver Glosario Interactivo](https://img.shields.io/badge/Ver%20Glosario-Interactivo-green?style=for-the-badge&logo=blogger)](https://sgevatschnaider.github.io/estadisticas-para-ciencia-de-datos/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_Glosario.html) |
| **Cuestionario Acad√©mico: Probabilidad Moderna** <br> <details><summary><strong>Resumen:</strong> <small><em>(haz clic para expandir)</em></small></summary><p>Evaluaci√≥n interactiva de 20 preguntas dise√±ada para desafiar y consolidar la intuici√≥n estad√≠stica. Contrasta los enfoques de integraci√≥n de Riemann y Lebesgue, explora el comportamiento de distribuciones continuas vs. discretas, y pone a prueba el dominio sobre los teoremas l√≠mite y tiempos de parada.</p></details> | [![Ver en GitHub](https://img.shields.io/badge/Ver%20en-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_Cuestionario.html) <br> [![Ver Cuestionario Interactivo](https://img.shields.io/badge/Ver%20Cuestionario-Interactivo-green?style=for-the-badge&logo=blogger)](https://sgevatschnaider.github.io/estadisticas-para-ciencia-de-datos/src/classroom/probabilidad/html/01_Fundamentos_Matematicos_Probabilidad_Cuestionario.html) |

| üìÑ Recurso | üì• Acceso |
| --- | --- |
| **01. La Geometr√≠a de la Aleatoriedad** <br>

| üìÑ Recurso | üì• Acceso |
| --- | --- |
| **01. La Geometr√≠a de la Aleatoriedad** <br>

<br>

<br> <details><summary><strong>Resumen:</strong> <em>(clic para expandir)</em></summary><p>Basado en <strong>Wasserman (Cap. 3)</strong>. Dejamos atr√°s la probabilidad b√°sica para entrar en el √°lgebra lineal. Visualizamos las variables aleatorias como vectores. Definimos la covarianza como un producto interno y la correlaci√≥n como un √°ngulo. Incluye simulaciones de c√≥mo la matriz de covarianza  deforma el espacio.</p></details> | [](https://www.google.com/search?q=./01_Geometria_de_la_Aleatoriedad.ipynb) [](https://www.google.com/search?q=https://colab.research.google.com/github/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/01_Geometria_de_la_Aleatoriedad.ipynb) |
| **02. La Normal Multivariante (MVN) y Whitening** <br>

<br>

<br> <details><summary><strong>Resumen:</strong> <em>(clic para expandir)</em></summary><p>El coraz√≥n del m√≥dulo. Estudiamos la densidad  de la MVN, sus isocontornos el√≠pticos y la descomposici√≥n espectral. Implementamos el proceso de <strong>"Whitening"</strong> (decorrelaci√≥n + estandarizaci√≥n) fundamental para el Deep Learning. Referencia cruzada con <strong>Kenett (Modern Statistics)</strong> para la implementaci√≥n computacional.</p></details> | [](https://www.google.com/search?q=./02_Normal_Multivariante_y_Whitening.ipynb) [](https://www.google.com/search?q=https://colab.research.google.com/github/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/02_Normal_Multivariante_y_Whitening.ipynb) |
| **APP HTML: Simulador de Elipsoides de Confianza** <br>

<br>

<br> <details><summary><strong>Resumen:</strong> <em>(clic para expandir)</em></summary><p>Visualizaci√≥n web interactiva (D3.js/Plotly). Permite manipular los valores de la matriz de covarianza  en tiempo real y observar c√≥mo rota y se estira la nube de puntos 3D. Visualiza planos de corte y distancias de Mahalanobis interactivas.</p></details> | [](https://www.google.com/search?q=./apps/simulador_mvn.html) |
| **03. Concentraci√≥n de la Medida (Teor√≠a del Aprendizaje)** <br>

<br>

<br> <details><summary><strong>Resumen:</strong> <em>(clic para expandir)</em></summary><p>¬øPor qu√© funciona el Machine Learning? Basado en <strong>Wasserman (Cap. 4 y 5)</strong>. Exploramos la Ley de los Grandes N√∫meros y, m√°s importante, las cotas de error no asint√≥ticas (Desigualdades de Hoeffding y Mill). Simulamos "la carrera de la convergencia" para ver cu√°n r√°pido convergen los estimadores en la pr√°ctica.</p></details> | [](https://www.google.com/search?q=./03_Concentracion_de_la_Medida.ipynb) [](https://www.google.com/search?q=https://colab.research.google.com/github/sgevatschnaider/estadisticas-para-ciencia-de-datos/blob/main/src/classroom/probabilidad/03_Concentracion_de_la_Medida.ipynb) |

---

## üìê Fundamentos Te√≥ricos (The Canon)

### 1. Vector de Medias y Matriz de Covarianza

Dada una variable aleatoria vectorial :

> **Intuici√≥n Ingenieril:**  contiene la informaci√≥n de la "forma" de los datos. Si  (Identidad), los datos son una esfera perfecta (ruido blanco isotr√≥pico).

### 2. Distancia de Mahalanobis

La distancia euclidiana miente en altas dimensiones si las variables est√°n correlacionadas. Usamos la m√©trica natural de la distribuci√≥n:

Esta distancia es **invariante a escalas y rotaciones**. En el notebook 02 veremos c√≥mo usarla para detectar anomal√≠as bancarias o de sensores.

---

## üíª Snippets de C√≥digo Esenciales

### Generaci√≥n de Datos MVN y Rotaci√≥n (Python)

```python
import numpy as np
import matplotlib.pyplot as plt

# 1. Definir par√°metros
mu = [0, 0]
sigma = [[1, 0.8], 
         [0.8, 1]]  # Alta correlaci√≥n positiva

# 2. Muestreo (Ingenier√≠a Inversa: Cholesky)
n = 1000
L = np.linalg.cholesky(sigma) # Descomposici√≥n de Cholesky
z = np.random.normal(size=(n, 2)) # Ruido blanco no correlacionado
x = z @ L.T + mu # Transformaci√≥n af√≠n: colorear el ruido

# 3. Visualizaci√≥n r√°pida
plt.scatter(x[:,0], x[:,1], alpha=0.5)
plt.title(f"MVN con correlaci√≥n {sigma[0][1]}")
plt.axis('equal')
plt.show()

```

---

## üìö Bibliograf√≠a Espec√≠fica del M√≥dulo

Este m√≥dulo se construye sobre los siguientes textos can√≥nicos (disponibles en la carpeta de referencias):

1. **[Wasserman]** *All of Statistics*
* *Cap√≠tulo 3:* Random Vectors (Base geom√©trica).
* *Cap√≠tulo 4:* Convergence (Fundamento del aprendizaje).
* *Cap√≠tulo 14:* Multivariate Models (La teor√≠a de la MVN).


2. **[Kenett & Zacks]** *Modern Statistics: A Computer-Based Approach*
* *Cap√≠tulo 2:* Data Visualization (Enfoque computacional).


3. **[Rotondi]** *Probability, Statistics and Simulation*
* *Cap√≠tulo 4:* Simulation of Random Variables (M√©todos de Monte Carlo).



---

## üó∫Ô∏è Roadmap del M√≥dulo

1. **Semana 1:** Vectores aleatorios, matrices de covarianza y visualizaci√≥n de correlaciones.
2. **Semana 2:** La Normal Multivariante a fondo. Diagonalizaci√≥n y PCA.
3. **Semana 3:** Desigualdades y l√≠mites. ¬øCu√°ntos datos necesito? (Hoeffding).
4. **Proyecto Final:** Detector de anomal√≠as basado en Mahalanobis sobre dataset real.

---
## üèÜ Proyecto Final: Detector de Anomal√≠as Multivariante

<p align="center">
  <img src="https://img.shields.io/badge/Dificultad-Avanzada-red?style=for-the-badge" alt="Dificultad">
  <img src="https://img.shields.io/badge/Herramienta-Jupyter_Notebook-F37626?style=for-the-badge&logo=jupyter" alt="Jupyter">
  <img src="https://img.shields.io/badge/Librer%C3%ADas-NumPy%20%7C%20SciPy-blue?style=for-the-badge" alt="Librer√≠as">
</p>



### üìù Descripci√≥n del Problema
En espacios de alta dimensi√≥n donde las variables est√°n correlacionadas, la distancia Euclidiana es enga√±osa. Un punto puede parecer "cercano" al centroide pero violar por completo la estructura de covarianza del sistema. 

El objetivo de este proyecto es implementar un sistema de **Detecci√≥n de Anomal√≠as (Outlier Detection)** desde cero utilizando la **Distancia de Mahalanobis**, aplic√°ndolo a un conjunto de datos real (por ejemplo, transacciones bancarias o lecturas de sensores industriales).

### üõ†Ô∏è Requisitos de Implementaci√≥n (Step-by-Step)

1. **Adquisici√≥n y Limpieza:**
   * Cargar un dataset multivariante continuo (se recomienda el *Credit Card Fraud Detection* de Kaggle o un dataset de telemetr√≠a).
   * Separar un subconjunto de datos "sanos" (inliers) para calibrar el modelo.

2. **Ajuste del Modelo Param√©trico (MVN):**
   * Calcular el vector de medias $\mu \in \mathbb{R}^d$.
   * Estimar la matriz de covarianza muestral $\Sigma \in \mathbb{R}^{d \times d}$.
   * *Control de estabilidad:* Verificar si $\Sigma$ es mal condicionada y aplicar regularizaci√≥n (Ridge/Tikhonov) o usar la pseudoinversa (`np.linalg.pinv`) si es necesario.

3. **Ingenier√≠a de Distancias:**
   * Implementar vectorizadamente el c√°lculo del cuadrado de la distancia de Mahalanobis para cada nueva observaci√≥n $x$:
     $$D_M^2(x) = (x - \mu)^T \Sigma^{-1} (x - \mu)$$

4. **Decisi√≥n Estad√≠stica y Umbrales:**
   * **Teor√≠a:** Sabiendo que $D_M^2$ sigue una distribuci√≥n $\chi^2$ (Chi-cuadrado) con $d$ grados de libertad.
   * **Pr√°ctica:** Utilizar `scipy.stats.chi2.ppf` para establecer un umbral de corte estricto (ej. $\alpha = 0.01$ o $\alpha = 0.001$). Todo punto que supere este umbral es clasificado como anomal√≠a.

5. **An√°lisis y Visualizaci√≥n:**
   * Proyectar los datos a 2D utilizando An√°lisis de Componentes Principales (PCA) calculado manualmente mediante la descomposici√≥n espectral de $\Sigma$.
   * Graficar las observaciones normales, las anomal√≠as detectadas y los isocontornos (elipsoides de confianza).

### üì¶ Entregables Esperados

* Un archivo `Proyecto_Mahalanobis.ipynb` completamente documentado.
* El c√≥digo debe estar estructurado en funciones limpias (ej. `fit_mvn(X)`, `mahalanobis_score(X_test, mu, cov)`, `predict_anomalies(scores, alpha)`).
* Un breve reporte final (en celdas Markdown) discutiendo:
  1. ¬øQu√© ventajas observaste respecto a usar simplemente una m√©trica Euclidiana?
  2. ¬øQu√© ocurre con la eficacia del detector si los datos subyacentes no son verdaderamente Gaussianos?

<details>
<summary>üí° <strong>Pista para la vectorizaci√≥n (clic para ver)</strong></summary>

Evita usar bucles `for` para calcular la distancia de miles de filas. Si `X` es tu matriz de datos centrada $(X - \mu)$ de dimensi√≥n $(n, d)$ y `InvSigma` es la matriz inversa $(d, d)$, puedes calcular todas las distancias simult√°neamente usando un producto de matrices y sumando a lo largo del eje correcto:

```python
delta = X_test - mu
# (n, d) @ (d, d) -> (n, d)
left_term = np.dot(delta, inv_sigma) 
# Producto elemento a elemento y suma por filas
D_squared = np.sum(left_term * delta, axis=1)
## ‚ö†Ô∏è Errores Comunes (Troubleshooting)

* **Matriz Singular:** Si `np.linalg.inv(Sigma)` falla, tu matriz de covarianza no es invertible (tienes variables colineales). *Soluci√≥n:* Usar `np.linalg.pinv` (pseudoinversa).
* **Maldici√≥n de la Dimensionalidad:** En alta dimensi√≥n, casi todos los puntos parecen "lejanos" (concentraci√≥n en la corteza). No conf√≠es en la intuici√≥n 2D/3D ciegamente.
* **Interpretaci√≥n de Correlaci√≥n:**  implica independencia **solo** si la distribuci√≥n es Gaussiana. En otros casos, puede haber dependencia no lineal.

```


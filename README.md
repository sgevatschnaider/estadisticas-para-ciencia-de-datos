# Applied Statistics for Data Science (Engineering & Research Track)

<p align="center">
  <img src="assets/portada%20.gif" alt="Visualizaci√≥n de conceptos: Geometr√≠a de Datos, Inferencia, Learning, Modelos Estructurados y Grafos" width="100%">
  <br>
  <sub style="font-size: 14px;">
    üîµ <b>Geometr√≠a & MVN</b> (M√≥d. I) &nbsp;|&nbsp;
    üü¢ <b>Inferencia Comp.</b> (M√≥d. II) &nbsp;|&nbsp;
    üü† <b>Regularizaci√≥n & ML</b> (M√≥d. III)
    <br>
    üî¥ <b>Causalidad & Tiempo</b> (M√≥d. IV) &nbsp;|&nbsp;
    üü£ <b>Grafos & Complejidad</b> (M√≥d. V)
  </sub>
</p>

---

## üìë Tabla de Contenidos
1. [Accesos r√°pidos](#accesos-r√°pidos)
2. [Descripci√≥n](#-descripci√≥n)
3. [Bibliograf√≠a base](#-bibliograf√≠a-base)
4. [Prop√≥sito del curso](#-prop√≥sito-del-curso)
5. [Syllabus detallado](#Ô∏è-syllabus-detallado)
6. [C√≥mo utilizar este material](#-c√≥mo-utilizar-este-material-instalaci√≥n-y-uso)
7. [Estructura del repositorio](#-estructura-del-repositorio-high-level)
8. [Uso y ejecuci√≥n](#Ô∏è-uso-y-ejecuci√≥n)
9. [Requisitos y nivel esperado](#-requisitos-y-nivel-esperado)
10. [Contribuciones](#-contribuciones)
11. [Licencia](#Ô∏è-licencia)

---

## üîó Accesos r√°pidos

> Acceso directo a las carpetas del repositorio con la teor√≠a (simuladores HTML) y el c√≥digo fuente (Notebooks).

<p align="center">
  <a href="https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/tree/main/src/classroom/probabilidad">
    <img src="https://img.shields.io/badge/M√ìDULO_I-Geometr√≠a-0366d6?style=for-the-badge" alt="M√ìDULO I">
  </a>
  <a href="https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/tree/main/src/classroom/inferencia">
    <img src="https://img.shields.io/badge/M√ìDULO_II-Inferencia-0366d6?style=for-the-badge" alt="M√ìDULO II">
  </a>
  <a href="https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/tree/main/src/classroom/learning">
    <img src="https://img.shields.io/badge/M√ìDULO_III-Learning-0366d6?style=for-the-badge" alt="M√ìDULO III">
  </a>
  <a href="https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/tree/main/src/classroom/pgm">
    <img src="https://img.shields.io/badge/M√ìDULO_IV-Estructurados-0366d6?style=for-the-badge" alt="M√ìDULO IV">
  </a>
  <a href="https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/tree/main/src/classroom/tiempo">
    <img src="https://img.shields.io/badge/M√ìDULO_V-Grafos-0366d6?style=for-the-badge" alt="M√ìDULO V">
  </a>
</p>

<p align="center">
  <a href="https://sgevatschnaider.github.io/estadisticas-para-ciencia-de-datos/" target="_blank" rel="noopener">
    <img alt="Live docs ‚Äî GitHub Pages" src="https://img.shields.io/badge/Live%20docs-GitHub%20Pages-2b3137?style=for-the-badge&logo=github" />
  </a>
  &nbsp;
  <a href="https://mybinder.org/v2/gh/sgevatschnaider/estadisticas-para-ciencia-de-datos/main" target="_blank" rel="noopener">
    <img alt="Live demos ‚Äî Binder" src="https://img.shields.io/badge/Live%20demos-Binder-f5a250?style=for-the-badge&logo=jupyter" />
  </a>
  &nbsp;
  <a href="https://colab.research.google.com/github/sgevatschnaider/estadisticas-para-ciencia-de-datos/" target="_blank" rel="noopener">
    <img alt="Open in ‚Äî Colab" src="https://img.shields.io/badge/Open%20in-Colab-F9AB00?style=for-the-badge&logo=googlecolab&logoColor=white" />
  </a>
</p>

---

## üéØ Descripci√≥n

Material docente de nivel **Ingenier√≠a** para Ciencia de Datos.

El curso asume conocimientos previos de estad√≠stica cl√°sica (por ejemplo: ANOVA y tests de hip√≥tesis b√°sicos) y se centra en la **caja blanca** de la ingenier√≠a estad√≠stica moderna: inferencia computacional, geometr√≠a de los datos, regularizaci√≥n y modelos gr√°ficos probabil√≠sticos (PGMs), con extensi√≥n a causalidad y series temporales.

<p align="center">
  <a href="https://www.python.org/">
    <img alt="Python" src="https://img.shields.io/badge/python-3.10%2B-blue">
  </a>
  <a href="https://www.r-project.org/">
    <img alt="R" src="https://img.shields.io/badge/R-4.x-276DC3">
  </a>
  <a href="https://julialang.org/">
    <img alt="Julia" src="https://img.shields.io/badge/Julia-1.x-9558B2">
  </a>
  <a href="https://github.com/psf/black">
    <img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg">
  </a>
  <a href="LICENSE">
    <img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-blue.svg">
  </a>
</p>

---

## üìö Bibliograf√≠a Base

Las referencias bibliogr√°ficas del programa se organizan en dos capas:

1. **The Canon**: textos vertebrales del curso (conceptos, m√©todos y marco unificado).  
2. **Foundations / Backbone**: fundamentos matem√°ticos y multivariantes que sostienen el nivel ‚ÄúEngineering & Research Track‚Äù.

### The Canon (textos centrales)

- **[Wasserman]** ‚Äî Larry Wasserman, *All of Statistics: A Concise Course in Statistical Inference*.  
- **[ESL]** ‚Äî Trevor Hastie, Robert Tibshirani, Jerome Friedman, *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*.  
- **[BDA3]** ‚Äî Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, Donald B. Rubin, *Bayesian Data Analysis (3rd Ed.)*.  
- **[Efron]** ‚Äî Bradley Efron, Trevor Hastie, *Computer Age Statistical Inference: Algorithms, Evidence, and Data Science*.  
- **[Bishop]** ‚Äî Christopher M. Bishop, *Pattern Recognition and Machine Learning*.  
- **[KollerFriedman]** ‚Äî Daphne Koller, Nir Friedman, *Probabilistic Graphical Models: Principles and Techniques*.  
- **[Pearl]** ‚Äî Judea Pearl, *Causality: Models, Reasoning, and Inference*.  
- **[ShumwayStoffer]** ‚Äî Robert H. Shumway, David S. Stoffer, *Time Series Analysis and Its Applications*.  

### Foundations / Mathematical Backbone (rigor y soporte formal)

Estas referencias sostienen resultados de convergencia, concentraci√≥n, multivariante y geometr√≠a usados a lo largo del curso:

- **[AxlerMeasure]** ‚Äî Sheldon Axler, *Measure, Integration & Real Analysis* (teor√≠a de medida e integraci√≥n).  
- **[Rosenthal]** ‚Äî Jeffrey Seth Rosenthal, *A First Look at Rigorous Probability Theory (2nd Ed.)* (probabilidad rigurosa y herramientas asint√≥ticas).  
- **[Mardia]** ‚Äî K. V. Mardia, J. T. Kent, J. M. Bibby, *Multivariate Analysis: Probability and Mathematical Statistics* (MVN, Wishart, teor√≠a multivariante cl√°sica).  
- **[HardleSimarFengler]** ‚Äî Wolfgang Karl H√§rdle, L√©opold Simar, Matthias R. Fengler, *Applied Multivariate Statistical Analysis* (multivariante aplicado y m√©todos modernos).  
- **[Chikuse]** ‚Äî Yasuko Chikuse, *Statistics on Special Manifolds* (Stiefel/Grassmann, estad√≠stica en variedades).  
- **[RotondiPedroniPievatolo]** ‚Äî Alberto Rotondi, Paolo Pedroni, Antonio Pievatolo, *Probability, Statistics and Simulation: With Application Programs Written in R* (Monte Carlo y verificaci√≥n computacional).  

### Lecturas complementarias (seg√∫n profundidad y orientaci√≥n)

- **[KenettZacksGedeck]** ‚Äî Ron S. Kenett, Shelemyahu Zacks, Peter Gedeck, *Modern Statistics: A Computer-Based Approach with Python* (enfoque computacional aplicado).  

---

## üéØ Prop√≥sito del curso

Conectar **probabilidad multivariante + √°lgebra lineal + inferencia computacional** con la **geometr√≠a de los datos** usada hoy en **ML/IA**: reducci√≥n de dimensi√≥n, regularizaci√≥n, modelos estructurados, grafos y m√©todos de simulaci√≥n/optimizaci√≥n.

---

## üó∫Ô∏è Syllabus detallado

## M√ìDULO I ‚Äî Vectores Aleatorios y Geometr√≠a de Datos

> **Enfoque:** la distribuci√≥n conjunta como objeto geom√©trico (subespacios, elipsoides, proyecciones) y la concentraci√≥n de la medida.

### üìÇ Ruta del m√≥dulo y Recursos

| Recurso | Enlace al Repositorio |
| :--- | :--- |
| **üíª C√≥digo Fuente** | [Ir a carpeta `src/classroom/probabilidad`](https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos/tree/main/src/classroom/probabilidad) |

### üó∫Ô∏è Temario Detallado

#### 1. Notaci√≥n matricial y geometr√≠a (Œº, Œ£)
- **Definiciones:** vector de medias Œº = E[X] y matriz de covarianza Œ£ = E[(X ‚àí Œº)(X ‚àí Œº)·µÄ].  
- **Propiedades:** simetr√≠a, semidefinida positiva e interpretaci√≥n geom√©trica (varianza por direcciones).  
- **Proyecciones:** varianza de u·µÄX y m√©trica inducida.  
- **Aplicaci√≥n:** feature scaling, covariance shift, distancia de Mahalanobis.

#### 2. Dependencia lineal vs. independencia estad√≠stica
- **Conceptos:** diferencia entre dependencia lineal (rango, singularidad) e independencia estad√≠stica (p(x,y) = p(x)p(y)).  
- **La falacia de la correlaci√≥n:** correlaci√≥n ‚â† independencia (excepto en distribuciones gaussianas).  
- **Aplicaci√≥n:** multicolinealidad en regresi√≥n, selecci√≥n de variables.

#### 3. Normal multivariante (MVN)
- **Definici√≥n:** densidad y forma cuadr√°tica.  
- **Geometr√≠a:** elipsoides de densidad y descomposici√≥n espectral: Œ£ = UŒõU·µÄ.  
- **Whitening (blanqueo):** Z = Œõ^(‚àí1/2) U·µÄ (X ‚àí Œº) para decorrelacionar datos.  
- **Aplicaci√≥n:** PCA, Gaussian Processes, Batch Normalization.

#### 4. Teor√≠a del aprendizaje (concentraci√≥n de la medida)
- **Convergencia:** LLN y CLT como convergencia estoc√°stica y aproximaci√≥n gaussiana.  
- **Desigualdades:** Chebyshev (cota por varianza) y Hoeffding (cota exponencial para variables acotadas).  
- **Aplicaci√≥n:** cotas de generalizaci√≥n, intervalos de confianza para m√©tricas.

### üìö Bibliograf√≠a Espec√≠fica ‚Äî M√≥dulo I

El m√≥dulo se apoya en textos de probabilidad rigurosa, teor√≠a multivariante y fundamentos geom√©tricos del aprendizaje estad√≠stico.

**Wasserman ‚Äî *All of Statistics***
- Chapter 3: Expectation and Variance  
- Chapter 4‚Äì5: Convergence of Random Variables and Inequalities  
- Chapter 14: Multivariate Models  

**Rosenthal ‚Äî *A First Look at Rigorous Probability Theory***
- Secciones sobre modos de convergencia y resultados LLN/CLT  
- Secciones sobre desigualdades y herramientas asint√≥ticas  

**Mardia, Kent & Bibby ‚Äî *Multivariate Analysis***
- Normal multivariante y propiedades geom√©tricas  
- Wishart y modelos multivariantes cl√°sicos  

**H√§rdle, Simar & Fengler ‚Äî *Applied Multivariate Statistical Analysis***
- PCA y reducci√≥n de dimensi√≥n  
- M√©todos multivariantes aplicados y geometr√≠a de datos  

**Hastie, Tibshirani & Friedman ‚Äî *The Elements of Statistical Learning***
- Chapter 2.4‚Äì2.5: Statistical Decision Theory  
- Chapter 3.5: Dimensionality Reduction  
- Secciones sobre bias‚Äìvariance tradeoff  

**Koller & Friedman ‚Äî *Probabilistic Graphical Models***
- Chapter 2‚Äì3: Conditional Independence and Factorization  

**Chikuse ‚Äî *Statistics on Special Manifolds* (opcional / Research Track)**
- Stiefel y Grassmann manifolds  
- Marco geom√©trico para extender modelos m√°s all√° de lo eucl√≠deo  

---

## M√ìDULO II ‚Äî Inferencia computacional y moderna

> **Enfoque:** superar l√≠mites de tests cl√°sicos mediante optimizaci√≥n y simulaci√≥n.

#### 5. Teor√≠a asint√≥tica y m√°xima verosimilitud (MLE)
- MLE como problema de optimizaci√≥n (gradiente y Hessiano; estimaci√≥n num√©rica).  
- Consistencia, eficiencia, informaci√≥n de Fisher y cota de Cram√©r‚ÄìRao.  
- **Aplicaci√≥n en DS/ML:** regresi√≥n log√≠stica (cross-entropy), entrenamiento de modelos probabil√≠sticos (Naive Bayes, HMM).  
- **Bibliograf√≠a:** **[Wasserman, Ch. 9]**, **[Efron & Hastie, Ch. 2]**.

#### 6. Bootstrap y m√©todos de resampling
- Estimaci√≥n del error est√°ndar sin f√≥rmulas cerradas.  
- Bootstrap param√©trico vs. no param√©trico; intervalos BCa.  
- **Aplicaci√≥n en DS/ML:** incertidumbre en m√©tricas (F1, AUC), bagging (Random Forest), stability selection.  
- **Bibliograf√≠a:** **[Wasserman, Ch. 8]**, **[Efron & Hastie, Ch. 10‚Äì11]**.

#### 7. Tests de hip√≥tesis en alta dimensionalidad
- Tests de Wald, Score y Likelihood Ratio Test (LRT).  
- Comparaciones m√∫ltiples: Bonferroni y FDR (Benjamini‚ÄìHochberg).  
- **Aplicaci√≥n en DS/ML:** A/B testing a escala, selecci√≥n de features en alta dimensi√≥n (gen√≥mica, texto).  
- **Bibliograf√≠a:** **[Wasserman, Ch. 10]**, **[Efron & Hastie, Ch. 15]**, **[ESL (cap√≠tulos de alta dimensi√≥n)]**.

---

## M√ìDULO III ‚Äî Aprendizaje estad√≠stico (regresi√≥n avanzada)

> **Enfoque:** trade-off sesgo‚Äìvarianza, geometr√≠a de proyecciones y selecci√≥n de modelos.

#### 8. Geometr√≠a de m√≠nimos cuadrados (OLS)
- Regresi√≥n como proyecci√≥n ortogonal; matriz sombrero H.  
- Teorema de Gauss‚ÄìMarkov y diagn√≥stico (leverage, distancia de Cook).  
- **Aplicaci√≥n en DS/ML:** baselines interpretables, detecci√≥n de puntos influyentes en producci√≥n.  
- **Bibliograf√≠a:** **[ESL, Ch. 3.2]**, **[Wasserman, Ch. 13]**.

#### 9. Regularizaci√≥n y selecci√≥n de modelos
- Maldici√≥n de la dimensionalidad y sobreajuste.  
- Ridge (L2): contracci√≥n y conexi√≥n con priors gaussianos.  
- Lasso (L1): sparsity y conexi√≥n con priors Laplace; Elastic Net.  
- Criterios de informaci√≥n: AIC y BIC; validaci√≥n cruzada como alternativa pr√°ctica.  
- **Aplicaci√≥n en DS/ML:** estabilidad en modelos, selecci√≥n autom√°tica de variables, early stopping.  
- **Bibliograf√≠a:** **[ESL, Ch. 3.4 y Ch. 7]**, **[Efron & Hastie, Ch. 7 y 16]**.

#### 10. Modelos lineales generalizados (GLM)
- Familia exponencial y funciones de enlace (log√≠stica y Poisson).  
- Algoritmo IRLS (Iteratively Reweighted Least Squares).  
- **Aplicaci√≥n en DS/ML:** clasificaci√≥n calibrada, modelado de conteos/demanda.  
- **Bibliograf√≠a:** **[ESL, Ch. 4.4]**, **[Efron & Hastie, Ch. 8]**.

---

## M√ìDULO IV ‚Äî Modelos estructurados, causalidad y tiempo

> **Enfoque:** modelar dependencias complejas, inferencia bayesiana y din√°mica.

#### 11. Probabilistic Graphical Models (PGMs)
- DAGs: factorizaci√≥n de la conjunta, independencia condicional y d-separation.  
- Plate notation para modelos jer√°rquicos.  
- **Aplicaci√≥n en DS/ML:** Naive Bayes, HMMs, modelos jer√°rquicos.  
- **Bibliograf√≠a:** **[Koller & Friedman, Ch. 2‚Äì4]**, **[Bishop, Ch. 8]**.

#### 12. Inferencia causal
- Correlaci√≥n vs. causalidad; intervenciones y operador do(¬∑).  
- Confounders, colliders y criterio back-door.  
- **Aplicaci√≥n en DS/ML:** A/B testing, uplift modeling, mitigaci√≥n de sesgos.  
- **Bibliograf√≠a:** **[Pearl, Ch. 1‚Äì3]**, **[Wasserman, Ch. 16‚Äì17]**.

#### 13. Inferencia bayesiana y MCMC
- Priors conjugados vs. no informativos; posterior como actualizaci√≥n de creencias.  
- MCMC: Metropolis‚ÄìHastings y diagn√≥stico b√°sico.  
- **Aplicaci√≥n en DS/ML:** Bayesian logistic regression, Bayesian optimization, cuantificaci√≥n de incertidumbre.  
- **Bibliograf√≠a:** **[BDA3, Ch. 1‚Äì3]**, **[Efron & Hastie, Ch. 13]**.

#### 14. Series temporales y modelos din√°micos
- Estacionariedad, autocorrelaci√≥n y modelos ARIMA.  
- State Space Models (SSM) y filtro de Kalman.  
- **Aplicaci√≥n en DS/ML:** forecasting (demanda, finanzas), tracking (IoT), comparaci√≥n con RNNs.  
- **Bibliograf√≠a:** **[Shumway & Stoffer, Ch. 1‚Äì3 y 6]**, **[Bishop, Ch. 13]**.

---

## M√ìDULO V ‚Äî Geometr√≠a moderna: grafos, complejidad y b√∫squeda

> **Enfoque:** expandir la geometr√≠a m√°s all√° de lo eucl√≠deo (grafos), din√°mica local (aut√≥matas) y optimizaci√≥n no convexa.

#### 15. Teor√≠a de grafos para ciencia de datos
- Matrices de adyacencia, conectividad, caminos, BFS/DFS.  
- **Aplicaci√≥n en DS/ML:** PageRank, comunidades, recomendadores, detecci√≥n de fraude.  
- **Bibliograf√≠a:** **[Material de c√°tedra]**.

#### 16. Espectros de grafos y geometr√≠a (spectral graph theory)
- Espectro del Laplaciano; autovalores y autovectores.  
- **Aplicaci√≥n en DS/ML:** spectral clustering, graph embeddings, fundamentos de GNNs.  
- **Bibliograf√≠a:** **[Material de c√°tedra]**, con referencias cruzadas a conceptos de espectro en **[ESL]** y **[Bishop]**.

#### 17. Modelos sobre grafos y unificaci√≥n
- Markov blankets, MRF (Markov Random Fields) y factor graphs.  
- Inferencia aproximada (loopy belief propagation).  
- **Aplicaci√≥n en DS/ML:** CRFs (secuencias), segmentaci√≥n, denoising.  
- **Bibliograf√≠a:** **[Koller & Friedman]**, **[Bishop, Ch. 8]**.

#### 18. Algoritmos evolutivos y programaci√≥n gen√©tica (GP)
- Optimizaci√≥n sin gradiente en paisajes no convexos.  
- GP: b√∫squeda en espacios de programas (symbolic regression).  
- **Aplicaci√≥n en DS/ML:** AutoML, ecuaciones interpretables, neuroevolution.  
- **Bibliograf√≠a:** **[Material de c√°tedra: Evolutivos/GP]**.

#### 19. Aut√≥matas celulares (CA) y din√°mica local
- Reglas locales y emergencia global; din√°mica en grillas.  
- **Aplicaci√≥n en DS/ML:** simulaci√≥n de propagaci√≥n (epidemias, tr√°fico), modelos generativos discretos.  
- **Bibliograf√≠a:** **[Material de c√°tedra: Aut√≥matas Celulares]**.

---

## üíª C√≥mo utilizar este material (Instalaci√≥n y Uso)

Tienes dos formas principales de consumir y ejecutar las clases de este repositorio.

### Opci√≥n A: En la nube (recomendado)
No necesitas instalar nada en tu computadora.

1. **Simuladores interactivos:** navega a los HTML desde las carpetas del repo o desde **GitHub Pages**.  
2. **Jupyter Notebooks:** usa los botones de **Binder** o **Colab** para abrir un entorno virtual y ejecutar el c√≥digo celda por celda.

### Opci√≥n B: Ejecuci√≥n local
Si prefieres tener los archivos en tu m√°quina:

1. Clona este repositorio:
   ```bash
   git clone https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos.git
   cd estadisticas-para-ciencia-de-datos
üß± Estructura del repositorio (high-level)

docs/ ‚Äî sitio GitHub Pages (material por m√≥dulo)

src/classroom/ ‚Äî notebooks, scripts y pr√°cticas por m√≥dulo

assets/ ‚Äî im√°genes, gifs y recursos visuales del curso

tests/ ‚Äî tests (si aplica)

requirements.txt / pyproject.toml ‚Äî dependencias

üõ†Ô∏è Uso y ejecuci√≥n
1) Clonar el repositorio
git clone https://github.com/sgevatschnaider/estadisticas-para-ciencia-de-datos.git
cd estadisticas-para-ciencia-de-datos
2) Crear entorno e instalar dependencias (Python)
python -m venv .venv

# Activar entorno (Linux/macOS):
source .venv/bin/activate

# Activar entorno (Windows):
# .venv\Scripts\activate

pip install -U pip
pip install -r requirements.txt
3) Calidad de c√≥digo (opcional, recomendado)
pre-commit install
pre-commit run --all-files
4) Ejecutar notebooks / pr√°cticas

Si trabajas con Jupyter Lab:

jupyter lab

Si usas VSCode:

Abre la carpeta del repositorio y ejecuta los archivos .ipynb con la extensi√≥n de Jupyter.

‚úÖ Requisitos y nivel esperado
Matem√°tica

Probabilidad y estad√≠stica cl√°sica (intervalos, tests b√°sicos, ANOVA).

√Ålgebra lineal (vectores, matrices, autovalores/autovectores).

Programaci√≥n

Python (lenguaje principal).

R / Julia como soporte opcional.

ü§ù Contribuciones

Issues y Pull Requests son bienvenidos.

Si vas a proponer cambios grandes (estructura, syllabus o tooling), por favor abre primero un Issue describiendo el objetivo y el impacto.

‚öñÔ∏è Licencia

Este material se distribuye bajo licencia MIT. Ver el archivo LICENSE
 para m√°s detalles.

